\section{Feasibility and Stability}
Using LQR in constrained systems can e.g.\ lead to input saturation and instability. However, even MPC does not guarantee feasibility and stability per se. In particular, in finite horizon MPC
\begin{itemize}
    \item Decrease in the prediction horizon can cause loss of stability properties.
    \item Depending on the initial condition, the CL trajectory may lead to states for which the optimization problem is infeasible after some steps, even without disturbance or model mismatch.
\end{itemize}
If we (could) solve the $\infty$-horizon control problem:
\begin{itemize}
    \item problem is feasible $\rightarrow$ closed loop trajectories will be always feasible.
    \item the cost is finite $\rightarrow$ states and inputs will converge asymptotically to the origin.
\end{itemize}
i.e.\ OL and CL would be identical.
\newpar{}
The goal of this section is hence to approximate the infinite horizon MPC to get feasibility and stability guarantees.
\subsection{Zero Terminal Constraint}
Given the terminal constraint $x_N = 0$.
\subsubsection{Feasibility}
Assume feasibility for $x(k)$ with optimal solution
\begin{equation*}
    \{u_0^*, u_1^*, \ldots, u_{N-1}^*\}, \quad \{x(k),x_1^*, x_2^*, \ldots, x_N^*\}
\end{equation*}

Applying the first control input $u_0^*$ to the system, the state will evolve as
\begin{equation*}
    x(k+1) = Ax(k) + Bu(k) = Ax(k) + B u_0^* = x_1^*
\end{equation*}
it follows directly that the sequence
\begin{equation*}
    \widetilde{U}=\{u_1^*, \ldots, u_{N-1}^*, 0\}\; \to \; \widetilde{X}=\{x_1^*, \ldots, x_N^*, \underbrace{Ax_N^* + Bu_N}_{0}\}
\end{equation*}
is feasible too. And therefore, recursive feasibility is guaranteed and the feasible set is \textbf{control invariant}.

\subsubsection{Stability}
Using the same (suboptimal) sequence $\widetilde{x}$ as above, the cost is given by
\begin{align*}
    J^*(x(k+1)) & \leq \widetilde{J}(x(k+1))                                                                                                         \\
                & = \sum_{i=1}^{N-1} I(x_i^*, u_i^*) + I(x_N^*, 0)                                                                                   \\
                & =\underbrace{\sum_{i=0}^{N-1} I(x_i^*, u_i^*)}_{J^*(x(k))} - \underbrace{I(x_0^*, u_0^*)}_{\geq 0}  + \underbrace{I(x_N^*, 0)}_{0} \\
                & \leq J^*(x(k))
\end{align*}
\begin{center}
    \includegraphics[width=0.8\linewidth]{images/06_fin_hor_stab.png}
\end{center}

\subsection{Terminal Subset Constraint}
The terminal constraint $x_N = 0$ reduces the size of the feasible set. By using a convex set $\mathcal{X}_f$ as terminal constraints for which a local control law is known (can be constructed), that has a finite cost to stay in this set, one can increase the region of attraction and hence the feasible set.
\subsubsection{Stability and Recursive Feasibility: Main Result}\label{stab_rec_feasibility}
To guarantee stability and recursive feasibility the following three properties have to hold:
\begin{enumerate}[leftmargin=24pt]
    \item[S1.1] Stage cost is positive definite, i.e.\ it is strictly positive and only zero at the origin.
    \item[S1.2] The terminal set $\mathcal{X}_f$ is \textbf{invariant} under the local control law $\kappa_f(x_i)$:
          \begin{equation*}
              x_{i+1} = Ax_i +B\kappa_f(x_i) \in \mathcal{X}_f, \quad \forall\: x_i \in \mathcal{X}_f
          \end{equation*}
          All state and input \textbf{constraints are satisfied} in $\mathcal{X}_f$:
          \begin{equation*}
              \mathcal{X}_f \subseteq \mathcal{X}, \: \kappa_f(x_i) \in \mathcal{U}, \quad \forall\: x_i \in \mathcal{X}_f
          \end{equation*}
    \item[S1.3] The terminal cost is a continuous \textbf{Lyapunov function} in the terminal set $\mathcal{X}_f$ and satisfies:
          \begin{equation*}
              I_f(x_{i+1})-I_f(x_i) \leq -I(x_i,\kappa_f(x_i)), \quad \forall\: x_i \in \mathcal{X}_f
          \end{equation*}
\end{enumerate}
where 1.\ \& 2.\ ensure recursive feasibility, 3.\ ensures stability.
\newpar{}
Under those three assumptions:

The closed-loop system under the MPC control law $u_0^*(x)$ is asymptotically stable and the set $\mathcal{X}_N$ (region of attraction) is positive invariant (and equal to the feasible set) for the system
\begin{equation*}
    x(k+1) = Ax(k) + Bu_0^*(x(k)).
\end{equation*}

This also generalizes to \textbf{nonlinear} system dynamics
\begin{equation*}
    x(k+1) = g(x(k),u_0^*(x(k)))
\end{equation*}
but there the computation of the terminal set $\mathcal{X}_f$ and the function $I_f$ can be very difficult.

% \subsubsection{Proof} we could add the outline of the proof here but I think this is not very beneficial in this summary since the reasoning is identical to the section before.
% Think the same, and we can grind it out on paper ;).
\subsubsection{Choice of Terminal Sets and Cost}

\begin{enumerate}
    \item Design a local control law $\kappa_f$ around $x=0$.
    \item Determine the terminal cost to stay in that set under the local control law.
    \item Compute the maximum invariant set for the closed loop system under the local control law hence $\mathcal{X}_f$.
\end{enumerate}

\paragraph{Linear System, Quadratic Cost}
For a linear system with quadratic cost
\begin{align*}
    J^*(x(k))    & = \min_{U} \;\textcolor{red}{x^\top_N P x_N} + \sum_{i=0}^{N-1} x_i^\top Q x_i + u_i^\top R u_I \\
    \text{s.t. } & x_{i+1} = Ax_i + Bu_i, \quad i = 0, \ldots, N-1                                                 \\
                 & x_i \in \mathcal{X}, u_k \in \mathcal{U}, \quad i = 0, \ldots, N-1                              \\
                 & \textcolor{red}{x_N \in \mathcal{X}_f}                                                          \\
                 & x_0 = x(k)
\end{align*}
one can design an unconstrained LQR controller as the local control law $\kappa_f(x_k)= F_\infty x_k$
\begin{equation*}
    F_\infty = -{\left(B^\top P_\infty B + R\right)}^{-1} B^\top P_\infty A
\end{equation*}
where the solution to the DARE $P_\infty$ can be chosen as the \textcolor{red}{terminal weight $P$}.

Then compute the \textcolor{red}{terminal set $\mathcal{X}_f$} to be the maximum invariant set for the closed-loop system $x_{k+1} = (A+BF_\infty)x_k$:
\begin{equation*}
    x_{k+1} = Ax_k + BF_\infty(x_k) \in \mathcal{X}_f, \quad \forall \: x_k \in \mathcal{X}_f
\end{equation*}
where all state and input constraints are satisfied in $\mathcal{X}_f$:
\begin{equation*}
    \mathcal{X}_f \subseteq \mathcal{X}, F_\infty x_k \in \mathcal{U}, \quad \forall \: x_k \in \mathcal{X}_f
\end{equation*}
This means, compute $\mathcal{X}_f$ for the CL system $(A+BF_{\infty})$, with constraints
\begin{equation*}
    \mathcal{X}_{cl} := \left\{x \left|
    \begin{bmatrix}
        A_x \\ A_u F_\infty
    \end{bmatrix}
    x \leq
    \begin{bmatrix}
        b_x \\
        b_u
    \end{bmatrix}\right.\right\}
\end{equation*}
This is the invariant terminal set used in the MPC.
\newpar{}
\textbf{Note} that this setup fulfills the conditions from the stability and Recursive Feasibility Theorem~\ref{stab_rec_feasibility}.

\paragraph{Horizon Length Versus Feasible Set}

For an MPC \textbf{without} terminal constraint, increasing $N$ shrinks the feasible set, as more constraints are added. One has
\begin{equation*}
    \mathcal{X}_{N+j} \subseteq \mathcal{X}_N
\end{equation*}
\newpar{}
For an MPC \textbf{with} terminal constraint, with larger $N$, the feasible set and region of attraction \textbf{grow}. The region of attraction ultimately approaches the maximum control invariant set. One has
\begin{equation*}
    \mathcal{X}_{N} \subseteq \mathcal{X}_{N+j}
\end{equation*}
Intuition: Given a trajectory with horizon length $N$, we can extend the trajectory arbitrarily using the control law $\kappa_i(x)$, while still obtaining feasible solutions.

\newpar{}
\ptitle{Practical Note}

In practice, one can enlarge $N$ and check stability by sampling.   % TODO: What does she mean by that? A: I think she means to sample some points and take their convex hull as a feasible set. So start with small N and increase until a sufficient feasible set results
