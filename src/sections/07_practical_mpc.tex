\section{Practical MPC}

\subsection{Reference Tracking}

A common task is to track a non-zero output set-point.

For a linear system with constraints, one can define the tracking task of the reference $r$ as
\begin{equation*}
    z(k) = Hx(k) \to r\in \mathbb{R}^{n_r} \text{ as } k \to \infty.
\end{equation*}
where $z(k)$ are the outputs that have to follow $r$.
\newpar{}
\textbf{Note}: The following concepts apply to piecewise constant references and not to general time-varying ones.

\subsubsection{Steady-State Target Problem}\label{steady_state_target_selection}

The reference is achieved by the target state $x_s$ if
\begin{equation*}
    z_s = Hx_s = r.
\end{equation*}
The target state should be a steady state, such that there exists an input that keeps the system at the target, i.e.
\begin{equation*}
    x_s = Ax_s +Bu_s
\end{equation*}
hence the target conditions become
\begin{equation*}
    \begin{array}{rcl}
        x_s  & = & Ax_s +Bu_s \\
        Hx_s & = & r
    \end{array}
    \Leftrightarrow
    \underbrace{\begin{bmatrix}
            I-A & -B \\
            H   & 0
        \end{bmatrix}}_{(n_x + n_r)\times(n_x + n_u)}
    \begin{bmatrix}
        x_s \\
        u_s
    \end{bmatrix}
    = \begin{bmatrix}
        0 \\
        r
    \end{bmatrix}
\end{equation*}
which can be easily solved for $(x_s, u_s)$.

\newpar{}
\ptitle{Multiple Solutions}

It is possible that there exist multiple feasible $(x_s, u_s)$ for a given reference $r$. Then the cheapest steady state can be used
\begin{align*}
    \min\quad    & u_s^\top R_s u_s                                \\
    \text{s.t. } & \begin{bmatrix}
                       I-A & -B \\
                       H   & 0
                   \end{bmatrix}
    \begin{bmatrix}
        x_s \\
        u_s
    \end{bmatrix}
    = \begin{bmatrix}
          0 \\
          r
      \end{bmatrix}                                               \\
                 & x_s \in \mathcal{X}, \quad u_s \in \mathcal{U}.
\end{align*}

\newpar{}
\ptitle{No Solution}

If no solution exists, then the reachable set point that is closest to $r$ can be computed
\begin{align*}
    \min\quad    & {\left(Hx_s -r\right)}^\top Q_s \left(Hx_s -r\right) \\
    \text{s.t. } & x_s = Ax_s + Bu_s                                    \\
                 & x_s \in \mathcal{X}, \quad u_s \in \mathcal{U}.
\end{align*}
Note that $u_s$ is unique in this case.

\subsubsection{Tracking Formulation}
A commonly-used formulation for tracking MPC cost is
\begin{equation*}
    \min_{U}\|z_{N}-Hx_{s}\|_{P_{z}}^{2}+\sum_{i=0}^{N-1}\|z_{i}-Hx_{s}\|_{Q_{z}}^{2}+\|u_{i}-u_{s}\|_{R}^{2}
\end{equation*}
% TODO: Why does one (not) use it compared to delta?

\subsubsection{Delta-Formulation for Tracking}
By introducing the delta formulation the tracking problem is transformed to the origin and therefore can be treated like a normal MPC problem.

\newpar{}

The deviation variables are given by
\begin{gather*}
    \Delta x = x - x_s \\
    \Delta u = u - u_s
\end{gather*}
which results for a linear system in a system model
\begin{align*}
    \Delta x_{k+1} & = x_{k+1}-x_s                \\
                   & = Ax_k + Bu_k -(Ax_s + Bu_s) \\
                   & = A\Delta x_k + B\Delta u_k
\end{align*}
and the constraints become
\begin{align*}
    G_x x \leq h_x \Rightarrow & \quad G_x\Delta x \leq h_x - G_x x_s  \\
    G_u u \leq h_u \Rightarrow & \quad G_u\Delta u \leq h_u - G_u u_s.
\end{align*}

\begin{center}
    \includegraphics[width=\linewidth]{07_constraints_transform.png}
\end{center}

\newpar{}
\ptitle{Resulting Optimization Problem}

The complete problem in Delta-Formulation then looks like
\begin{align*}
    \Delta U^* = \arg\min_{\Delta U} \quad & \sum_{i=0}^{N-1} \Delta x_i^\top Q \Delta x_i + \Delta u_i^\top R \Delta u_i + V_f(\Delta x_N) \\
    \text{s.t.} \quad                      & \Delta x_0 = \Delta x(k) = x(k)-x_s                                                            \\
                                           & \Delta x_{i+1} = A \Delta x_i + B \Delta u_i                                                   \\
                                           & G_x \Delta x_i \leq h_x - G_x x_s                                                              \\
                                           & G_u \Delta u_i \leq h_u - G_u u_s                                                              \\
                                           & \Delta x_N \in \mathcal{X}_f
\end{align*}
where $x_s, u_s$ is assumed to be determined beforehand by~\ref{steady_state_target_selection}.

\begin{center}
    \includegraphics[width=0.7\linewidth]{07_delta-formulation.png}
\end{center}

where the final input to the system is
\begin{equation*}
    u_0^* = \Delta u_0^* + u_s.
\end{equation*}

Note:

If the target steady-state is uniquely defined by the reference, we can also include the target condition as a constraint in the MPC problem.

\subsubsection{Convergence}

Assume target is feasible with $x_s \in \mathcal{X}, u_s \in \mathcal{U}$ and choose terminal weight $V_f(x)$ and constraint $\mathcal{X}_f$ as in the regulation case satisfying (i.e.\ we found $V_f(x), \mathcal{X}_f$ only for the regulation case):
\begin{gather*}
    \mathcal{X}_f \subseteq \mathcal{X}, \: Kx \in \mathcal{U} \: \forall x \in \mathcal{X}_f \\
    V_f(x(k+1)) - V_f(x(k)) \leq -I(x(k),Kx(k)) \: \forall x \in \mathcal{X}_f
\end{gather*}
\newpar{}
As the dynamics are identical in the Delta-formulation and the original system, the same Lyapunov function $V_f$ can be used.
\newpar{}
However, the terminal set constraint must be modified. In the Delta-formulation we require
\begin{equation*}
    \Delta x_N \in \mathcal{X}_f
\end{equation*}
which imposes
\begin{equation*}
    x_N \in \left\{x_s + \Delta x_N, \Delta x_N \in \mathcal{X}_f\right\} \subseteq \mathcal{X}
\end{equation*}
on the true system. Therefore the following condition is required: If in addition the target reference $x_s, u_s$ is such that
\begin{equation*}
    x_s \oplus \mathcal{X}_f \subseteq \mathcal{X}, \: K\Delta x + u_s \in \mathcal{U}, \: \forall \Delta x \in \mathcal{X}_f
\end{equation*}
then the closed-loop system converges to the target reference, i.e.
\begin{equation*}
    x(k) \to x_s \text{ and therefore } z(k) = Hx(k) \to r \text{ for } k \to \infty.
\end{equation*}

\subsubsection{Terminal Set}

Due to the transformation the set of feasible targets may be significantly reduced.

\newpar{}

In the following example the blue line represents the state constraints and the green line the terminal set.

\newpar{}

\begin{tabularx}{\linewidth}{YY}
    Regulation case:                                          & Tracking using a shifted terminal set: \\

    \includegraphics[width=\linewidth]{07_terminal_set_1.png} &

    \includegraphics[width=\linewidth]{07_terminal_set_2.png}
\end{tabularx}
\begin{center}
    Set of feasible targets:

    \includegraphics[width=0.5\linewidth]{07_terminal_set_3.png}
\end{center}

\newpar{}
\ptitle{Terminal Set Scaling}

To enlarge the set of feasible targets one can scale the terminal set.
\begin{equation*}
    \mathcal{X}_f^{\text{scaled}} = \alpha \mathcal{X}_f
\end{equation*}
\begin{center}
    \includegraphics[width=0.5\linewidth]{07_terminal_set_4.png}
\end{center}

The scaling factor $\alpha$ has to be chosen such that the state and input constraints are still satisfied.
Targets at the boundary of the constraints hence $x_N = x_s$, correspond to a zero terminal set in the regulation case.
\newpar{}
\textbf{Note} that scaling preserves invariance.
\subsubsection{Offset-Free Reference Tracking}
Goal: Track constant reference $r$, i.e.\ $z(k) = Hy(k) \to r$ for $k \to \infty$. If system is stabilized in the presence of the disturbance then it converges to set point with zero offset.
\newpar{}
\ptitle{Algorithm}

At each sampling time:
\begin{enumerate}
    \item Estimate state and disturbance $\hat{x}$, $\hat{d}$
    \item Solve steady-state target problem using $\hat{d}$
    \item Solve MPC problem:
\end{enumerate}
\begin{align*}
    \min_U       & \sum_{i=0}^{N-1} (x_i - x_s)^T Q (x_i - x_s)                                      \\
                 & + {(u_i - u_s)}^T R (u_i - u_s) + V_f(x_N - x_s)                                  \\
    \text{s.t. } & x_0 = \hat{x}(k), \quad d_0 = \hat{d}(k)                                          \\
                 & x_{i+1} = Ax_i + Bu_i + B_d d_i, \quad i = 0, \dots, N                            \\
                 & d_{i+1} = d_i, \quad i = 0, \dots, N                                              \\
                 & x_i \in \mathcal{X}, \quad u_i \in \mathcal{U}, \quad x_N - x_s \in \mathcal{X}_f
\end{align*}
\newpar{}
\ptitle{Constant Disturbances}

Constant disturbances cause the system trajectory to deviate from nominal dynamics. They act as follows on the true plant:
\begin{align*}
    x(k+1) & = Ax(k) + Bu(k) + B_d d \\
    y(k)   & = Cx(k) + C_d d
\end{align*}

\paragraph{Augmented Model}

The constant disturbance can be included in to the dynamic system model as follows:
\begin{align*}
    x_{k+1} & = Ax_k + Bu_k + B_d d_k \\
    d_{k+1} & = d_k                   \\
    y_k     & = Cx_k + C_d d_k
\end{align*}
with $d \in \mathbb{R}^{n_d}$.

The only restriction on the choice of $B_d, C_d$: observability of the augmented model.
\newpar{}
\ptitle{Observability of Augmented System}

The augmented system is observable if and only if $(A, C)$ is observable and
\begin{equation*}
    \begin{bmatrix}
        A - I & B_d \\
        C     & C_d
    \end{bmatrix}
\end{equation*}
has full column rank, i.e.\ rank $= n_x + n_d$.
\newpar{}
Note that
\begin{itemize}
    \item The number of measured outputs must be large enough: $n_d \leq n_y$.
    \item This is known as Hautus observability condition.
\end{itemize}
\newpar{}
Intuitively, the condition can be explained as follows: At steady-state
\begin{equation*}
    \begin{bmatrix}
        A - I & B_d \\
        C     & C_d
    \end{bmatrix}
    \begin{bmatrix}
        x_s \\
        d_s
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 \\
        y_s
    \end{bmatrix}
\end{equation*}
and given $y_s$, $d_s$ must be uniquely defined.

\paragraph{Linear State Estimation}
To improve the estimate of the disturbance and to account for non-measurable states, an observer can be used. For the augmented model we get
    {\small
        \begin{gather*}
            \begin{bmatrix}
                \hat{x}(k + 1) \\
                \hat{d}(k + 1)
            \end{bmatrix}=
            \begin{bmatrix}
                A & B_d \\
                0 & I
            \end{bmatrix}
            \begin{bmatrix}
                \hat{x}(k) \\
                \hat{d}(k)
            \end{bmatrix}
            +\begin{bmatrix}
                B \\
                0
            \end{bmatrix}
            u(k)
            \\
            +\begin{bmatrix}
                L_x \\
                L_d
            \end{bmatrix}
            (-y(k) + C\hat{x}(k) + C_d \hat{d}(k))
        \end{gather*}
    }
where the last summand corrects the state \textbf{and} disturbance estimate. On convergence, this term vanishes, revealing the steady-state equations.
\newpar{}
The \textbf{error dynamics} are:
{\small
\begin{align*}
    \begin{bmatrix}
        \eta(k + 1) \\
        \eta_d (k+1)
    \end{bmatrix}
     & = \begin{bmatrix}
             x(k + 1) - \hat{x}(k + 1) \\
             d(k + 1) - \hat{d}(k + 1)
         \end{bmatrix}
    \\
     & =
    \left(
    \begin{bmatrix}
        A & B_d \\
        0 & I
    \end{bmatrix}
    +
    \begin{bmatrix}
        L_x \\
        L_d
    \end{bmatrix}
    \begin{bmatrix}
        C & C_d
    \end{bmatrix}
    \right)
    \begin{bmatrix}
        x(k) - \hat{x}(k) \\
        d(k) - \hat{d}(k)
    \end{bmatrix}
\end{align*}
}
\newpar{}
To obtain zero estimation error, the estimator gain $L = \begin{bmatrix} L_x \\ L_d \end{bmatrix}$ must be chosen such that the error dynamics are asymptotically stable.

\newpar{}
\ptitle{Lemma: Offset-Free Steady-State Estimation}

Suppose the observer is asymptotically stable and $n_y = n_d$. The observer steady state satisfies:
\begin{equation*}
    \begin{bmatrix}
        A - I & B \\
        C     & 0
    \end{bmatrix}
    \begin{bmatrix}
        \hat{x}_\infty \\
        u_\infty
    \end{bmatrix}
    =
    \begin{bmatrix}
        - B_d \hat{d}_\infty \\
        y_\infty - C_d \hat{d}_\infty
    \end{bmatrix}
\end{equation*}

In words: The observer output $C \hat{x}_\infty + C_d \hat{d}_\infty$ tracks $y_\infty$ without offset!

\paragraph{Steady-State Selection}
The knowledge of the disturbance estimate allows us to reformulate the steady-state selection problem as
\begin{align*}
    x_s & = Ax_s + Bu_s + B_d \hat{d}_\infty \\
    z_s & = H(Cx_s + C_d \hat{d}_\infty) = r
\end{align*}
which shows that both, the steady-state and the target are modified to account for the disturbance.
\newpar{}
As we don't have access to $\hat{d}_\infty$, we use the best possible estimate for $\hat{d}_\infty$, namely $\hat{d}$ for the target selection problem, yielding
\begin{equation*}
    \begin{bmatrix}
        A - I & B \\
        HC    & 0
    \end{bmatrix}
    \begin{bmatrix}
        x_s \\
        u_s
    \end{bmatrix}
    =
    \begin{bmatrix}
        - B_d \hat{d} \\
        r - HC_d \hat{d}
    \end{bmatrix}
\end{equation*}

For regulation, we can simply set $r=0$.

\paragraph{Offset-free Tracking: Main Result}

Let $\kappa(\hat{x}(k), \hat{d}(k), r) = u_0^\star$ be the estimation-based control law.

Assume
\begin{itemize}
    \item $n_d = n_y$
    \item the RHC is recursively feasible and unconstrained for $k \geq j$
    \item and the closed-loop system
          \begin{align*}
              x(k+1)        = & Ax(k) + B \kappa(\hat{x}(k), \hat{d}(k), r) + B_d d    \\
              \hat{x}(k+1)  = & (A + L_x C) \hat{x}(k) + (B_d + L_x C_d) \hat{d}(k)    \\
                              & + B \kappa(\hat{x}(k), \hat{d}(k), r) - L_x y(k)       \\
              \hat{d}(k+1)  = & L_d C \hat{x}(k) + (I + L_d C_d) \hat{d}(k) - L_d y(k)
          \end{align*}
          converges ($\hat{x}(k)\rightarrow \hat{x}_{\infty}$, $\hat{d}(k)\rightarrow \hat{d}_{\infty}$, $y(k)\rightarrow y_{\infty}$ for $k\rightarrow \infty$).
\end{itemize}
Then $z(k) = Hy(k) \to r$ as $k \to \infty$, i.e.\ we track the reference in presence of the disturbance.

