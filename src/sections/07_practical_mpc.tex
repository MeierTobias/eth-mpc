\section{Practical MPC}

\subsection{Reference Tracking}

A common task is to track a non-zero output set-point.

For a linear system with constraints, one can define the tracking task of the reference $r$ as
\begin{equation*}
    z(k) = Hx(k) \to r\in \mathbb{R}^{n_r} \text{ as } k \to \infty.
\end{equation*}
where $z(k)$ are the outputs that have to follow $r$.
\newpar{}
\textbf{Note}: The following concepts apply to piecewise constant references and not to general time-varying ones.

\subsubsection{Steady-State Target Problem}\label{steady_state_target_selection}

The reference is achieved by the target state $x_s$ if
\begin{equation*}
    z_s = Hx_s = r.
\end{equation*}
The target state should be a steady state, such that there exists an input that keeps the system at the target, i.e.
\begin{equation*}
    x_s = Ax_s +Bu_s
\end{equation*}
hence the target conditions become
\begin{equation*}
    \begin{array}{rcl}
        x_s  & = & Ax_s +Bu_s \\
        Hx_s & = & r
    \end{array}
    \Leftrightarrow
    \underbrace{\begin{bmatrix}
            I-A & -B \\
            H   & 0
        \end{bmatrix}}_{(n_x + n_r)\times(n_x + n_u)}
    \begin{bmatrix}
        x_s \\
        u_s
    \end{bmatrix}
    = \begin{bmatrix}
        0 \\
        r
    \end{bmatrix}
\end{equation*}
which can be easily solved for $(x_s, u_s)$.

\newpar{}
\ptitle{Multiple Solutions}

It is possible that there exist multiple feasible $(x_s, u_s)$ for a given reference $r$. Then the cheapest steady state can be used
\begin{align*}
    \min\quad    & u_s^\top R_s u_s                                \\
    \text{s.t. } & \begin{bmatrix}
                       I-A & -B \\
                       H   & 0
                   \end{bmatrix}
    \begin{bmatrix}
        x_s \\
        u_s
    \end{bmatrix}
    = \begin{bmatrix}
          0 \\
          r
      \end{bmatrix}                                               \\
                 & x_s \in \mathcal{X}, \quad u_s \in \mathcal{U}.
\end{align*}

\newpar{}
\ptitle{No Solution}

If no solution exists, then the reachable set point that is closest to $r$ can be computed
\begin{align*}
    \min\quad    & {\left(Hx_s -r\right)}^\top Q_s \left(Hx_s -r\right) \\
    \text{s.t. } & x_s = Ax_s + Bu_s                                    \\
                 & x_s \in \mathcal{X}, \quad u_s \in \mathcal{U}.
\end{align*}
Note that $u_s$ is unique in this case.

\subsubsection{Tracking Formulation}
A commonly-used formulation for tracking MPC cost is
\begin{equation*}
    \min_{U}\|z_{N}-Hx_{s}\|_{P_{z}}^{2}+\sum_{i=0}^{N-1}\|z_{i}-Hx_{s}\|_{Q_{z}}^{2}+\|u_{i}-u_{s}\|_{R}^{2}
\end{equation*}
% TODO: Why does one (not) use it compared to delta?

\subsubsection{Delta-Formulation for Tracking}
By introducing the delta formulation the tracking problem is transformed to the origin and therefore can be treated like a normal MPC problem.

\newpar{}

The deviation variables are given by
\begin{gather*}
    \Delta x = x - x_s \\
    \Delta u = u - u_s
\end{gather*}
which results for a linear system in a system model
\begin{align*}
    \Delta x_{k+1} & = x_{k+1}-x_s                \\
                   & = Ax_k + Bu_k -(Ax_s + Bu_s) \\
                   & = A\Delta x_k + B\Delta u_k
\end{align*}
and the constraints become
\begin{align*}
    G_x x \leq h_x \Rightarrow & \quad G_x\Delta x \leq h_x - G_x x_s  \\
    G_u u \leq h_u \Rightarrow & \quad G_u\Delta u \leq h_u - G_u u_s.
\end{align*}

\begin{center}
    \includegraphics[width=\linewidth]{07_constraints_transform.png}
\end{center}

\newpar{}
\ptitle{Resulting Optimization Problem}

The complete problem in Delta-Formulation then looks like
\begin{align*}
    \Delta U^* = \arg\min_{\Delta U} \quad & \sum_{i=0}^{N-1} \Delta x_i^\top Q \Delta x_i + \Delta u_i^\top R \Delta u_i + V_f(\Delta x_N) \\
    \text{s.t.} \quad                      & \Delta x_0 = \Delta x(k) = x(k)-x_s                                                            \\
                                           & \Delta x_{i+1} = A \Delta x_i + B \Delta u_i                                                   \\
                                           & G_x \Delta x_i \leq h_x - G_x x_s                                                              \\
                                           & G_u \Delta u_i \leq h_u - G_u u_s                                                              \\
                                           & \Delta x_N \in \mathcal{X}_f
\end{align*}
where $x_s, u_s$ is assumed to be determined beforehand by~\ref{steady_state_target_selection}.

\begin{center}
    \includegraphics[width=0.7\linewidth]{07_delta-formulation.png}
\end{center}

where the final input to the system is
\begin{equation*}
    u_0^* = \Delta u_0^* + u_s.
\end{equation*}

Note:

If the target steady-state is uniquely defined by the reference, we can also include the target condition as a constraint in the MPC problem.

\subsubsection{Convergence}

Assume target is feasible with $x_s \in \mathcal{X}, u_s \in \mathcal{U}$ and choose terminal weight $V_f(x)$ and constraint $\mathcal{X}_f$ as in the regulation case satisfying (i.e.\ we found $V_f(x), \mathcal{X}_f$ only for the regulation case):
\begin{gather*}
    \mathcal{X}_f \subseteq \mathcal{X}, \: Kx \in \mathcal{U} \: \forall x \in \mathcal{X}_f \\
    V_f(x(k+1)) - V_f(x(k)) \leq -I(x(k),Kx(k)) \: \forall x \in \mathcal{X}_f
\end{gather*}
\newpar{}
As the dynamics are identical in the Delta-formulation and the original system, the same Lyapunov function $V_f$ can be used.
\newpar{}
However, the terminal set constraint must be modified. In the Delta-formulation we require
\begin{equation*}
    \Delta x_N \in \mathcal{X}_f
\end{equation*}
which imposes
\begin{equation*}
    x_N \in \left\{x_s + \Delta x_N, \Delta x_N \in \mathcal{X}_f\right\} \subseteq \mathcal{X}
\end{equation*}
on the true system. Therefore the following condition is required: If in addition the target reference $x_s, u_s$ is such that
\begin{equation*}
    x_s \oplus \mathcal{X}_f \subseteq \mathcal{X}, \: K\Delta x + u_s \in \mathcal{U}, \: \forall \Delta x \in \mathcal{X}_f
\end{equation*}
then the closed-loop system converges to the target reference, i.e.
\begin{equation*}
    x(k) \to x_s \text{ and therefore } z(k) = Hx(k) \to r \text{ for } k \to \infty.
\end{equation*}

\subsubsection{Terminal Set}

Due to the transformation the set of feasible targets may be significantly reduced.

\newpar{}

In the following example the blue line represents the state constraints and the green line the terminal set.

\newpar{}

\begin{tabularx}{\linewidth}{YY}
    Regulation case:                                          & Tracking using a shifted terminal set: \\

    \includegraphics[width=\linewidth]{07_terminal_set_1.png} &

    \includegraphics[width=\linewidth]{07_terminal_set_2.png}
\end{tabularx}
\begin{center}
    Set of feasible targets:

    \includegraphics[width=0.5\linewidth]{07_terminal_set_3.png}
\end{center}

\newpar{}
\ptitle{Terminal Set Scaling}

To enlarge the set of feasible targets one can scale the terminal set.
\begin{equation*}
    \mathcal{X}_f^{\text{scaled}} = \alpha \mathcal{X}_f
\end{equation*}
\begin{center}
    \includegraphics[width=0.5\linewidth]{07_terminal_set_4.png}
\end{center}

The scaling factor $\alpha$ has to be chosen such that the state and input constraints are still satisfied.
Targets at the boundary of the constraints hence $x_N = x_s$, correspond to a zero terminal set in the regulation case.
\newpar{}
\textbf{Note} that scaling preserves invariance.
\subsubsection{Offse-Free Control}

\subsection{Enlarging the Feasible Set}