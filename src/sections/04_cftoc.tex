\section{Constrained Finite Time Optimal Control (CFTOC)}

\subsection{Constrained Linear Optimal Control}

For a linear model the CFTOC problem is given by
\begin{align*}
    J^*(x(k)) =            & \min_U \: I_f(x_N) + \sum_{i=0}^{N-1}I(x_i,u_i)                    \\
    \text{subject to}\quad & x_{i+1} = Ax_i +Bu_i, \quad i = 0, \ldots, N-1                     \\
                           & x_i \in \mathcal{X}, u_i \in \mathcal{U}, \quad i = 0, \ldots, N-1 \\
                           & x_N \in \mathcal{X}_f                                              \\
                           & x_0 = x(k)
\end{align*}
where $I(x_i,u_i)$ is the stage cost, $I_f(x_N)$ represents an approximation of the tail cost and $\mathcal{X}_f$ of the tail constraints, respectively. $N$ is the time horizon and $\mathcal{X,U,X}_f$ are polyhedral regions.

\newpar{}
\ptitle{Feasible Set}

The feasible set describes a set of initial states for which the optimal control problem is feasible. It is defined only by the constraints and not by the cost:
\begin{align*}
    \mathcal{X}_N = & \left\{ x_0 \in \mathbb{R}^n | \exists\left(u_0, \ldots, u_{N-1}\right) \text{such that } x_i\in\mathcal{X}, u_i\in\mathcal{U} \right. \\
                    & \left.i=0,\ldots, N-1, x_N\in\mathcal{X}_f, \text{where } x_{i+1}=Ax_i + Bu_i\right\}
\end{align*}

Or in other words, the feasible set describes initial conditions from which it is possible to get into the final set $\mathcal{X}_f$ within $N-1$ steps.
\newpar{}
In the convex case, the convex hull of a set of feasible solutions can be used as approximation of $\mathcal{X}_N$.

\subsubsection{Quadratic Cost CFTOC}

The cost function that incorporates a squared euclidean norm is composed of
\begin{align*}
    I_f(x_N)   & = x_N^T P x_N                     \\
    I(x_i,U_i) & = x_i^\top Q x_i + u_i^\top R u_i
\end{align*}
with $P\succeq0, Q\succeq0, R\succ0$.

\newpar{}

The \textbf{quadratic cost CFTOC problem}
\begin{align*}
    J^*(x(k)) =            & \min_U \: x_N^T P x_N + \sum_{i=0}^{N-1}x_i^\top Q x_i + u_i^\top R u_i \\
    \text{subject to}\quad & x_{i+1} = Ax_i +Bu_i, \quad i = 0, \ldots, N-1                          \\
                           & x_i \in \mathcal{X}, u_i \in \mathcal{U}, \quad i = 0, \ldots, N-1      \\
                           & x_N \in \mathcal{X}_f                                                   \\
                           & x_0 = x(k)
\end{align*}

can be transformed into a QP problem
\begin{align*}
    \min_{z\in\mathbb{R}^n} & \frac{1}{2}z^\top Hz + q^\top z + r \\
    \text{subject to}\quad  & Gz \leq h                           \\
                            & Az = b
\end{align*}

either with (\ref{cftoc_QP_with_subs}) or without (\ref{cftoc_QP_without_subs}) substitution of the future states $X$.

\newpar{}
\ptitle{Notation}

In the following we use
\begin{itemize}
    \item $n_x$: dimension of state space
    \item $n_u$: dimension of input
    \item $n_z$: dimension of $z$ for~\ref{cftoc_QP_without_subs}
    \item $n_w$: dimension of $w$ for~\ref{cftoc_QP_with_subs}
    \item $n_{in,x}$: number of state inequality constraints
    \item $n_{in,u}$: number of input inequality constraints
\end{itemize}

\paragraph{Construction of QP Without Substitution}\label{cftoc_QP_without_subs}

This approach keeps the state equations as equality constraints. The CFTOC problem is transformed into the QP problem parametrized in the initial condition $x(k)$  % TODO: In the lecture they say this approach would be more efficient. In terms of comp. cost or just for matrix bastli?
\begin{align*}
    J^*(x(k)) =            & \min_{z}\begin{bmatrix}
                                         z^\top & x(k)
                                     \end{bmatrix}
    \underbrace{\begin{bmatrix}
                        \bar{H} & 0 \\
                        0       & Q
                    \end{bmatrix}}_{\widetilde{H}}
    \begin{bmatrix}
        z^\top & {x(k)}^\top
    \end{bmatrix}^\top                                       \\
    \text{subject to}\quad & G_{in} z \leq w_{in} +E_{in} x(k) \\
                           & G_{eq} z = E_{eq} x(k)
\end{align*}
where
\begin{equation*}
    z = \begin{bmatrix}
        x_1^\top & \cdots & x_N^\top & u_0^\top & \cdots & u_{N-1}^\top
    \end{bmatrix}^\top \in \mathbb{R}^{n_z = N(n_x + n_u)}
\end{equation*}
and $\widetilde{H}\in \mathbb{R}^{(n_z+n_x) \times (n_z+n_x)} \geq 0$ as $J(x(k),U) \geq 0$ by assumption. % TODO: I added H>=0 also here (we had it only in the substitution paragraph but I think it's >=0 in both cases).

\newpar{}
\ptitle{Cost}

The cost submatrix $\bar{H}$ is
\begin{equation*}
    \bar{H} = \left[
        \begin{array}{cccc|cccc} % ChkTex 44
            Q &        &   &   &   &        &   \\
              & \ddots &   &   &   &        &   \\
              &        & Q &   &   &        &   \\
              &        &   & P &   &        &   \\
            \hline % ChkTex 44
              &        &   &   & R &        &   \\
              &        &   &   &   & \ddots &   \\
              &        &   &   &   &        & R
        \end{array}
        \right]
\end{equation*}

This can be constructed using the Matlab function

\begin{small}
    \texttt{barH = blkdiag(kron(eye(N-1),Q),P,kron(eye(N),R))}
\end{small}

\newpar{}
\ptitle{Equality Constraints}

The equalities are given from the system dynamics
\begin{equation*}
    x_{i+1} = Ax_i + Bu_i
\end{equation*}
can be rewritten as
\begin{equation*}
    G_{eq} z = E_{eq} x(k)
\end{equation*}
with
    {\small
        \begin{gather*}
            G_{eq} = \left[
                \begin{array}{cccc|cccc} % ChkTex 44
                    I  &   &        &   & -B &    &        &    \\
                    -A & I &        &   &    & -B &        &    \\
                       &   & \ddots &   &    &    & \ddots &    \\
                       &   & -A     & I &    &    &        & -B
                \end{array}
                \right] \in \mathbb{R}^{N\cdot n_x \times n_z}\\
            E_{eq} = \begin{bmatrix}
                A^\top & 0 & \cdots & 0
            \end{bmatrix}^\top \in \mathbb{R}^{N\cdot n_x \times n_x}
        \end{gather*}
    }

\newpar{}
\ptitle{Inequality Constraints}

The inequality constraints
\begin{gather*}
    \mathcal{X} = \{x|A_x x \leq b_x\} \\
    \mathcal{U} = \{u|A_u u \leq b_u\} \\
    \mathcal{X}_f = \{x|A_f x \leq b_f\}
\end{gather*}
can be rewritten as
\begin{equation*}
    G_{in} z \leq w_{in} + E_{in} x(k)
\end{equation*}
with
\begin{align*}
    G_{in} & \in \mathbb{R}^{(n_{in,x}+n_{in,u})\times n_z} \\
           & =\left[
        \begin{array}{cccc|cccc} % ChkTex 44
            0   &        &     &     & 0   &        &        &     \\
            \hline % ChkTex 44
            A_x &        &     &     & 0   &        &        &     \\
                & \ddots &     &     &     & \ddots &        &     \\
                &        & A_x &     &     &        & 0      &     \\
                &        &     & A_f &     &        &        & 0   \\
            \hline % ChkTex 44
            0   &        &     &     & A_u &        &        &     \\
                & \ddots &     &     &     & A_u    &        &     \\
                &        & 0   &     &     &        & \ddots &     \\
                &        &     & 0   &     &        &        & A_u
        \end{array}
    \right]                                                 \\
\end{align*}
\begin{gather*}
    w_{in}\in \mathbb{R}^{(n_{in,x}+n_{in,u})\times 1}, \quad E_{in} \in \mathbb{R}^{(n_{in,x}+n_{in,u})\times n_x}\\
    w_{in} = \begin{bmatrix}
        b_x                    \\
        \cmidrule(lr){1-1} b_x \\
        \vdots                 \\
        b_x                    \\
        b_f                    \\
        \cmidrule(lr){1-1} b_u \\
        b_u                    \\
        \vdots                 \\
        b_u                    \\
        b_u
    \end{bmatrix}, \quad
    E_{in} =\begin{bmatrix}
        -A_x                 \\
        \cmidrule(lr){1-1} 0 \\
        \vdots               \\
        0                    \\
        0                    \\
        \cmidrule(lr){1-1} 0 \\
        0                    \\
        \vdots               \\
        0                    \\
        0
    \end{bmatrix}
\end{gather*}

\paragraph{Construction of QP With Substitution}\label{cftoc_QP_with_subs}

The future states are only dependent on the current state and the applied input sequence. Hence they can be uniquely constructed from these and can therefore be substituted. To do so the same method as for the LQR batch approach (\ref{unconst_lqr}) is used:
\begin{align*}
    \underbrace{\begin{bmatrix}
                        x_1    \\
                        x_2    \\
                        \vdots \\
                        x_N
                    \end{bmatrix}}_{X \in \mathbb{R}^{N\cdot n_x}} = &
    \underbrace{\begin{bmatrix}
                        A      \\
                        A^2    \\
                        \vdots \\
                        A^N
                    \end{bmatrix}}_{S^x} x(k) +
    \underbrace{\begin{bmatrix}
                        B        & 0      & \cdots & 0 \\
                        AB       & B      & \cdots & 0 \\
                        \vdots   & \ddots & \ddots & 0 \\
                        A^{N-1}B & \cdots & AB     & B
                    \end{bmatrix}}_{S^u \in \mathbb{R}^{(N\cdot n_x)\times (N\cdot n_u)}}
    \underbrace{\begin{bmatrix}
                        u_0    \\
                        u_1    \\
                        \vdots \\
                        u_{N-1}
                    \end{bmatrix}}_{U}                                      \\
    X =                                              & S^x x(k) + S^u U
\end{align*}

\newpar{}
\ptitle{Cost}

By substituting the $X$ vector in the cost function of~\ref{cftoc_QP_without_subs}, one can rewrite the cost only depending on $U$ and $x(k)$ (parametrized in the initial condition)
\begin{align*}
    J^*(x(k), U)=          & \min_{U}\begin{bmatrix}
                                         U^\top & {x(k)}^\top
                                     \end{bmatrix}
    \underbrace{\begin{bmatrix}
                        H & F^\top \\
                        F & Y
                    \end{bmatrix}}_{\widetilde{H}}
    {\begin{bmatrix}
         U^\top & {x(k)}^\top
     \end{bmatrix}}^\top                                 \\
    \text{subject to}\quad & GU \leq w + Ex(k)
\end{align*}
where $\widetilde{H}\in \mathbb{R}^{(N\cdot n_u + n_x)\times (N\cdot n_u + n_x)}\geq 0$ since $J(x(k),U) \geq 0$ by assumption.

\newpar{}
\ptitle{Inequality Constraints}

The inequality constraints
\begin{gather*}
    \mathcal{X} = \{x|A_x x \leq b_x\} \\
    \mathcal{U} = \{u|A_u u \leq b_u\} \\
    \mathcal{X}_f = \{x|A_f x \leq b_f\}
\end{gather*}
can be rewritten as
\begin{equation*}
    GU\leq w + Ex(k)
\end{equation*}
with
\begin{align*}
    G & \in \mathbb{R}^{(n_{in,u} + n_{in,x})\times (N\cdot n_u)} \\
      & = \begin{bmatrix}
              A_u                   & 0             & \cdots & 0      \\
              0                     & A_u           & \cdots & 0      \\
              \vdots                & \vdots        & \ddots & \vdots \\
              0                     & 0             & \cdots & A_u    \\
              \cmidrule(lr){1-4}  0 & 0             & \cdots & 0      \\
              A_x B                 & 0             & \cdots & 0      \\
              A_x AB                & A_x B         & \cdots & 0      \\
              \vdots                & \vdots        & \ddots & \vdots \\
              A_f A^{N-1} B         & A_f A^{N-2} B & \cdots & A_f B
          \end{bmatrix}
\end{align*}
\begin{gather*}
    w \in \mathbb{R}^{(n_{in,u} + n_{in,x})\times 1},\quad E \in \mathbb{R}^{(n_{in,u} + n_{in,x})\times n_x}\\
    w = \begin{bmatrix}
        b_u                    \\
        b_u                    \\
        \vdots                 \\
        b_u                    \\
        \cmidrule(lr){1-1} b_x \\
        b_x                    \\
        b_x                    \\
        \vdots                 \\
        b_f
    \end{bmatrix}, \quad
    E = \begin{bmatrix}
        0                       \\
        0                       \\
        \vdots                  \\
        0                       \\
        \cmidrule(lr){1-1} -A_x \\
        -A_x A                  \\
        -A_x A^2                \\
        \vdots                  \\
        -A_f A^N
    \end{bmatrix}
\end{gather*}
Note that $w$ is structurally different to $w_{in}$ from~\ref{cftoc_QP_without_subs}.

\paragraph{Comparison: Substitution vs.\ No Substitution}

\renewcommand{\arraystretch}{1.3}
\setlength{\oldtabcolsep}{\tabcolsep}\setlength\tabcolsep{6pt}
\begin{tabularx}{\linewidth}{@{}lll@{}}
                   & Substitution                  & No Substitution               \\
    \cmidrule{2-3}
    \# opt.\ vars. & $N n_u$                       & $N(n_x + n_u)$                \\
    benefits       & less opt.\ vars.              &                               \\
                   & less constraints              & sparse constr.\ ($\propto N$) \\
    drawbacks      & complicated constr.           & more opt.\ vars.              \\
                   & more constr.\ ($\propto N^2$) &                               % TODO: Why?
\end{tabularx}
\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{\oldtabcolsep}
Note that substitution transforms input constraints into state constraints, making them more involved in general. Hence, no substitution is often preferable. For small $N$ and large $n_x$ however, substitution can be more efficient.

\paragraph{State Feedback Solution}

As $n_x>=1$, the CFTOC problem is a \textbf{multiparametric quadratic program (mp-QP)} in general with the following solution properties:

\begin{itemize}
    \item $u_0^*$ is of the form (nonlinear feedback policy)
          \begin{equation*}
              u_0^*=\kappa(x(k)),\quad\forall x(k)\in\mathcal{X}_0
          \end{equation*}
          with $\kappa:\mathbb{R}^n \to \mathbb{R}^m$ cont., \textbf{piecewise affine} on polyhedra
          \begin{equation*}
              \kappa  =\kappa(x)=F^j x + g^j, \quad\mathrm{if}\quad x\in CR^j,\quad j=1,\cdots,N^r
          \end{equation*}
    \item The polyhedral sets for the individual control laws
          \begin{equation*}
              CR^j=\{x\in\mathbb{R}^n|H^j x\leq K^j\},j=1,\cdots,N^r
          \end{equation*}
          are a partition of the feasible polyhedron $\mathcal{X}_0$.
    \item $J^*(x(k))$ is \textbf{convex}, \textbf{piecewise quadratic} on polyhedra.
\end{itemize}
\newpar{}
\textbf{Explicit MPC} addresses how to compute this solution.
\begin{center}
    \includegraphics[width = \linewidth]{04_CFTOC_control_law.png}
\end{center}

\subsubsection[1-Norm and Inf-Norm Cost]{1-Norm and $\infty$-Norm Cost CFTOC}

% The cost function that incorporates the $p=1$ or $p=\infty$ norm is composed of
% \begin{align*}
%     I_f(x_N)   & = {\lVert Px_N \rVert}_p                          \\
%     I(x_i,U_i) & = {\lVert Qx_i \rVert}_p + {\lVert Ru_i \rVert}_p
% \end{align*}
% with $P,Q,R$ having full column rank. % TODO: I didn't find it in the slides. But just uncomment it if it's important.

The $1$-norm and $\infty$-norm cost CFTOC can be transformed into LPs of the form
\begin{align*}
    \min_{z\in\mathbb{R}^n}C^T z  \\
    \text{subj.\ to } Gz & \leq h \\
    Az                   & =b
\end{align*}
The key method is to reformulate the problem in \textbf{epigraph form} using auxiliary variables.

\paragraph[linf Minimization]{$l_{\infty}$ Minimization}

The constrained \(\ell_\infty\) (Chebyshev) minimization problem is:
\begin{gather*}
    \min_{x \in \mathbb{R}^n} \|x\|_\infty \\
    \text{subj.\ to } Fx \leq g
\end{gather*}
The peak absolute value in $x$ is the largest value of all $\{-x_i, x_i\}$. Hence, the cost can be rewritten as maximum of linear functions
\begin{equation*}
    \min_{x \in \mathbb{R}^n} \left[\max \{x_1, \dots, x_n, -x_1, \dots, -x_n\}\right]
\end{equation*}

\newpar{}
\ptitle{Auxiliary Variable Formulation}

In order to obtain a LP, one uses an equivalent formulation with \textit{one} auxiliary variable $t$:
\begin{gather*}
    \min_{x, t} t \\
    \text{subj.\ to } -\mathbf{1} t \leq x \leq \mathbf{1} t\\
    Fx \leq g
\end{gather*}
where $\mathbf{1}$ indicates a vector of ones and $-\mathbf{1} t \leq x \leq \mathbf{1} t$ bounds the absolute value of every element of $x$ with a \textit{common} scalar variable $t$.

\newpar{}
\ptitle{Application to CFTOC}\label{l_inf_CFTOC}

The $\infty$-norm minimization CFTOC reformulation introduces a \textit{scalar} auxiliary variable for each state of the trajectory
\begin{align*}
    z & := \{ \varepsilon_{0}^x, \dots, \varepsilon_{N}^x, \varepsilon_{0}^u, \dots, \varepsilon_{N-1}^u, u_0^\top, \dots, u_{N-1}^\top \} \in \mathbb{R}^s, \\
    s & := (m + 1) N + N + 1
\end{align*}
This yields the $\infty$-norm minimization CFTOC \textbf{cost}
\begin{equation*}
    \min_z \varepsilon_{0}^x + \dots + \varepsilon_{N}^x + \varepsilon_{0}^u + \dots + \varepsilon_{N-1}^u
\end{equation*}
Using
\begin{align*}
    x_i & = A^i x_0 + \sum_{j=0}^{i-1} A^j B u_{i-1-j} \\
    x_N & = A^N x_0 + \sum_{j=0}^{N-1} A^j B u_{N-1-j}
\end{align*}
the state and input \textbf{norm constraints} amount to
\begin{align*}
    \text{subj.\ to } \  & -\mathbf{1}_n \varepsilon_{x_i} \leq \pm Q x_i, \\
                         & -\mathbf{1}_r \varepsilon_{x_N} \leq \pm P x_N, \\
                         & -\mathbf{1}_m \varepsilon_{u_i} \leq \pm R u_i
\end{align*}
% TODO: I think we know deez nuts
% The standard \textbf{MPC constraints} are
% \begin{align*}
%      & x_i\in X,                              \\
%      & u_i \in U,                             \\
%      & x_N \in X_f,                           \\
%      & x_0 = x(k), \quad i = 0, \dots, N - 1.
% \end{align*}
The problem results in the following \textbf{standard LP}:
% TODO: What is c? :O Does it mean that we weigh the different norm bounds differently? Why would one?
\begin{gather*}
    \min_z \              c^\top z                                                                                                                                                              \\
    \text{subj.\ to } \   \bar{G} z \leq \bar{w} + \bar{S} x(k),                                                                                                                                \\
    \bar{G}               = \begin{bmatrix} G_\varepsilon & G_u \\ 0 & G\end{bmatrix}, \bar{S} = \begin{bmatrix} S_\varepsilon \\ S \end{bmatrix}, \bar{w}= \begin{bmatrix} w_\varepsilon \\ w \end{bmatrix}
\end{gather*}
Using this formulation, given $x(k)$, the optimal control sequence $U^*$ can be obtained via an LP solver.

\paragraph[l1 Minimization]{$l_{1}$ Minimization}

The constrained \(\ell_1\) minimization problem is defined as:
\begin{gather*}
    \min_{x \in \mathbb{R}^n} \|x\|_1 \\
    \text{subj.\ to } Fx \leq g
\end{gather*}
again using the maximum of linear functions method yields
\begin{equation*}
    \min_{x \in \mathbb{R}^n} \left[ \sum_{i=1}^{m} \max \{x_i, -x_i\} \right]
\end{equation*}

\newpar{}
\ptitle{Auxiliary Variable Formulation}

The equivalent formulation introduces a \textit{vector} of auxiliary variables $t \in \mathbb{R}^n$, yielding
\begin{gather*}
    \min_{x \in \mathbb{R}^n, t \in \mathbb{R}^n} \mathbf{1}^\top t, \\
    \text{subj.\ to } -t \leq x \leq t, \\
    Fx \leq g
\end{gather*}
The constraint $-t \leq x \leq t$ bounds the absolute value of each component of $x$ with each \textit{component} of the vector variable $t$.

\newpar{}
\ptitle{Application to CFTOC}
% TODO: should we write this one out?
Apply the auxiliary variable formulation similar to~\ref{l_inf_CFTOC}. However,
\begin{itemize}
    \item Introduce a vector $\varepsilon_i^x \in \mathbb{R}^n$ of auxiliary variables for each state in the trajectory
    \item Sum all $\mathbf{1}^\top \varepsilon_i^x$ in the cost function
    \item Remember that the equality constraints are now element wise for each $x_i$ and corresponding entry in $\varepsilon_i^x$
\end{itemize}

\paragraph[l1, linf State Feedback Solution]{$l_{1}, l_{\infty}$ State Feedback Solution}

The CFTOC problem
% TODO: Why are there no equality constraints?? Wieso liegt hier Stroh in der Ecke?
\begin{align*}
    \min_{z\in\mathbb{R}^n}c^T z                            \\
    \text{subj.\ to } \bar{G}z & \leq \bar{w} + \bar{S}x(k)
\end{align*}
is again a mp-LP with the following solution properties:
\begin{itemize}
    \item $u_0^*$ has the form:
          \begin{align*}
              u_0^* = \kappa(x(0)), \quad \forall x(0) \in \mathcal{X}_0,
          \end{align*}
          where $\kappa : \mathbb{R}^n \to \mathbb{R}^m$ is cont.\, piecewise affine on polyhedra:
          \begin{align*}
              \kappa(x) = F^j x + g^j, \quad \text{if } x \in CR^j, \quad j = 1, \dots, N^r
          \end{align*}
    \item The polyhedral sets
          \begin{equation*}
              CR^j = \{x \in \mathbb{R}^n \mid H^j x \leq K^j\}, \quad j = 1, \dots, N^r
          \end{equation*}
          are a partition of the feasible polyhedron $\mathcal{X}_0$.
    \item In case of multiple optimizers, a \textbf{piecewise affine} control law exists.
    \item The value function $J^*(x(0))$ is \textbf{convex} and \textbf{piecewise affine} (not convex as for QP) on polyhedra.
\end{itemize}

\newpar{}
\ptitle{Location of Optimizer in State Space}

The type of cost function influences the location of the optimizer in state space. See
\begin{itemize}
    \item\ \ref{optimizer_location_LP} for LP
    \item\ \ref{optimizer_location_QP} for QP
\end{itemize}

\subsection{Common Constraints}
\subsubsection{Polytopic Constraints}
\ptitle{Input Constraints}
\begin{equation*}
    u_{\min} \leq u \leq u_{\max} \quad \Leftrightarrow \quad \begin{bmatrix}
        -\mathbb{I} \\
        \mathbb{I}
    \end{bmatrix} u \leq \begin{bmatrix}
        -u_{\min} \\
        u_{\max}
    \end{bmatrix}
\end{equation*}

\newpar{}
\ptitle{Rate Constraints}
\begin{equation*}
    \|x_K - x_{k+1}\|_\infty \leq \alpha \quad \Leftrightarrow \quad \begin{bmatrix}
        \mathbb{I}  & -\mathbb{I} \\
        -\mathbb{I} & \mathbb{I}
    \end{bmatrix}\begin{bmatrix}
        x_k \\
        x_{k+1}
    \end{bmatrix} \leq \bm{1} \alpha
\end{equation*}

\newpar{}
\ptitle{Magnitude Constraints}

\begin{equation*}
    \|C x_k\|_\infty \leq \alpha \quad \Leftrightarrow \quad \begin{bmatrix}
        C \\ -C
    \end{bmatrix} x_k \leq \bm{1} \alpha
\end{equation*}