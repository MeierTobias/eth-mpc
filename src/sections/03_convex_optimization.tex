\section{Convex Optimization}
\subsection{Problem Formulation and Terminology}
\noindent\begin{align*}
    \min_{x\in\mathrm{dom}(f)} & f(x)                          \\
    \text{subj.\ to\;\; }      & g_i(x)\leq0\quad i=1,\ldots,m \\
                               & h_{i}(x)=0\quad i=1,\ldots,p
\end{align*}
where
\renewcommand{\arraystretch}{1.3}
\setlength{\oldtabcolsep}{\tabcolsep}\setlength\tabcolsep{3pt}

\begin{tabularx}{\linewidth}{@{}lXX@{}}
    $x=\begin{bmatrix}
               x_1 & \cdots & x_n
           \end{bmatrix}^\top$
                                                                                            & \multicolumn{2}{l}{Decision/optimization variable                                }  \\
    $f:\;\mathrm{dom}(f) \to \mathbb{R}$                                                    & \multicolumn{2}{l}{Objective function ($\mathrm{dom}(f) \subseteq \mathbb{R}^n$) }  \\
    $g_i:\;\mathbb{R}^n \to \mathbb{R}$                                                     & \multicolumn{2}{l}{Inequality constraint functions                               }  \\
    $h_i:\;\mathbb{R}^n \to \mathbb{R}$                                                     & \multicolumn{2}{l}{Equality constraint functions                                  } \\
    \multicolumn{2}{l}{$\mathcal{X} := \{ x\in \mathrm{dom}(f) | g_i(x)\leq0, h_i(x)=0 \}$} & Feasible set
\end{tabularx}

\newpar{}
\ptitle{Terminology}
\begin{itemize}
    \item \textbf{Feasible point:} point in the feasible set $\mathcal{X}$
    \item \textbf{Strictly feasible point:}\newline point in the interior of $\mathcal{X}$ (i.e., $g_i(x)<0$)
    \item \textbf{Optimal value:} $p^*=f(x^*) = \min\limits_{x\in\mathcal{X}} f(x)$
    \item \textbf{Optimizer:}\newline $x^*$ that achieves $p^*$ i.e.\ $f(x^*)\leq f(x)\; \forall x\in \mathcal{X}$.\newline Not necessarily unique.
    \item \textbf{Unbounded below:} $p^*=-\infty$
    \item \textbf{Infeasible:} $\mathcal{X}=\emptyset$ i.e.\ $p^* = \infty$
    \item \textbf{Unconstrained:} $\mathcal{X}=\mathbb{R}^n$
\end{itemize}

\renewcommand{\arraystretch}{1}
\setlength\tabcolsep{\oldtabcolsep}

\subsubsection{Constraints}
$g_i(x)$ is \textbf{active} at $\bar{x}$ if $g_i(\bar{x})=0$. Thus, equality constraints are always active.

\newpar{}
A \textbf{redundant} constraint does not change the feasible set.

\subsubsection{Optimality}
$x\in \mathcal{X}$ is \textbf{locally optimal} if, for some $R>0$
\begin{equation*}
    y\in \mathcal{X},\; {\|x-y\|}<R\quad \Rightarrow\quad f(x)\leq f(y)
\end{equation*}
$x\in \mathcal{X}$ is \textbf{globally optimal} if
\begin{equation*}
    f(x)\leq f(y)\quad \forall y\in \mathcal{X}
\end{equation*}


\subsection{Convex Sets}
A set $\mathcal{X}$ is convex \textbf{iff} for any pair of points $x$ and $y$ in $\mathcal{X}$:
\begin{equation*}
    \lambda x+(1-\lambda)y\in\mathcal{X},\forall\lambda\in[0,1],\forall x,y\in\mathcal{X}
\end{equation*}
\newpar{}
\ptitle{Convex Combination}

Any point $x$ of the form
\begin{equation*}
    x=\theta_1x_1+\theta_2x_2+...+\theta_k x_k\mathrm{~with~}\theta_1+...+\theta_k=1,\theta_i\geq0
\end{equation*}
is called convex combination of $x_1,\cdots,x_k$.
\subsubsection{Hyperplanes and Halfspaces}
A \textbf{hyperplane} is defined by $\left\{x \in \mathbb{R}^n \mid a^\top x = b\right\}$ for $a \neq 0$, where $a \in \mathbb{R}^n$ is the normal vector to the hyperplane.
\newpar{}
A \textbf{halfspace} is everything on one side of a hyperplane $\left\{x \in \mathbb{R}^n \mid a^\top x \leq b\right\}$ for $a \neq 0$. It can either be open (strict inequality) or closed (non-strict inequality).
\newpar{}
Hyperplanes are affine and convex, halfspaces are convex.

\subsubsection{Polyhedra and Polytopes}
A \textbf{polyhedron} is the intersection of a finite number of closed halfspaces:
\begin{equation*}
    P := \left\{ x \mid a_i^\top x \leq b_i, i = 1, \ldots, m \right\} = \left\{ x \mid Ax \leq b \right\}
\end{equation*}
where
\begin{equation*}
    A := \begin{bmatrix} a_1 & a_2 & \ldots & a_m \end{bmatrix}^\top \quad \text{and} \quad b := \begin{bmatrix} b_1 & b_2 & \ldots & b_m \end{bmatrix}^\top
\end{equation*}
\newpar{}
A \textbf{polytope} is a bounded polyhedron.
\newpar{}
Polyhedra and polytopes are always convex.
\subsubsection{Ellipsoids}
An ellipsoid is a set defined as
\begin{equation*}
    \{x \mid {(x - x_c)}^\top A^{-1}(x - x_c) \leq 1\}
\end{equation*}
where $x_c$ is the centre of the ellipsoid, and $A > 0$ (i.e. $A$ is positive definite).

\subsubsection{Norm Balls}
The norm ball, defined by $\{x|\;||x-x_{\mathrm{c}}||\leq r\}$ where $x_{\mathrm{c}}$ is the centre of the ball
and $r\geq0$ is the radius, is always convex for any norm.
\newpar{}
\ptitle{Euclidian Ball}

The Euclidean ball $B(x_c,r)$ is a special case of the ellipsoid, for which $A=r^2 \mathbb{I}$, so that $B(x_c,r):=\{x| \|x-x_c\|_2\leq r\}$

\subsubsection{Set Operations}
The intersection of convex sets is convex, whereas the union of convex sets is not necessarily convex.
\subsection{Convex Functions}
A function $f:\text{dom}(f) \rightarrow \mathbb{R}$ is convex \textbf{iff} $\text{dom}(f)$ is convex and $\forall x,y \in \text{dom}(f)$
\begin{equation*}
    f(\lambda x + (1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y),\quad \forall \lambda \in (0,1)
\end{equation*}
In words, a line connecting any two points on the graph of the function lies above the graph (epigraph).

\newpar{}
The function $f:\text{dom}(f) \rightarrow \mathbb{R}$ is strictly convex if this inequality is strict.

\newpar{}
The function $f$ is \textbf{concave} \textbf{iff} $\operatorname{dom}(f)$ is convex and $-f$ is convex.

\newpar{}
\ptitle{First Order Condition}

A differentiable function $f: \operatorname{dom}(f) \to \mathbb{R}$ with a convex domain is convex \textbf{iff}
\begin{equation*}
    f(y) \geq f(x) + \nabla {f(x)}^{\top}(y-x), \quad \forall x, y \in \operatorname{dom}(f)
\end{equation*}
i.e.\ the first-order approximation must be a global underestimator.

\newpar{}
\ptitle{Second Order Condition}

A twice-differentiable function $f : \text{dom}\,(f) \to \mathbb{R}$ with convex domain $\text{dom}\,(f)$ is convex \textbf{iff}
\begin{equation*}
    \nabla^2 f(x) \geq 0, \quad \forall x \in \text{dom}\,(f), \quad \nabla^2 {f(x)}_{ij} = \frac{\partial^2 f(x)}{\partial x_i \partial x_j}
\end{equation*}
\newpar{}
$f$ is called \textbf{strictly convex} if $\text{dom}(f)$ is convex and the Hessian fulfills
\begin{equation*}
    \nabla^2 f(x) > 0, \quad \forall x\in \operatorname{dom}(f)
\end{equation*}

\subsubsection{Level and Sublevel Sets}
The \textbf{level set} $L_{\alpha}$ of a function $f$ for value $\alpha$ is the set of all $x \in \operatorname{dom}(f)$ for which $f(x) = \alpha$:
\begin{equation*}
    L_{\alpha} := \{ x | x \in \operatorname{dom}(f),\; f(x) = \alpha \}
\end{equation*}
\newpar{}
For $f:\mathbb{R}^2 \to \mathbb{R}$ these are \textbf{contour lines} of constant height.

The \textbf{sublevel set} $C_{\alpha}$ of a function $f$ for value $\alpha$ is defined by
\begin{equation*}
    C_{\alpha} := \{x | x \in \text{dom}(f),\; f(x) \leq \alpha\}
\end{equation*}

\newpar{}
$f$ is convex $\Rightarrow$ sublevel sets of $f$ are convex $\forall \alpha$.

But, sublevel sets of $f$ are convex $\forall \alpha \nRightarrow f$ is convex.

\subsubsection{Examples of Convex Functions}
\ptitle{Convex}
\begin{itemize}
    \item Affine functions: $ ax + b,\; \forall a,b\in \mathbb{R}$
    \item Exponential functions: $e^{ax}\; \forall a\in \mathbb{R}$
    \item Powers: $x^\alpha$ on domain $\mathbb{R}_{++}$ for $\alpha \leq 0, \alpha \geq1$
    \item Vector norms on $\mathbb{R}^n$:
          \begin{align*}
              ||x||_p      & ={(\sum_{i=1}^n|x|^p)}^{1/p},\mathrm{~for~}p\geq1 \\
              ||x||_\infty & =\max_i|x_i|
          \end{align*}
\end{itemize}
\newpar{}
\ptitle{Convexity Preserving Operations}
\begin{itemize}
    \item Nonnegative weighted sums: $\sum_{i=1}^{n} \theta_i f_i(x)$ for $\theta_i \geq 0$
    \item Composition with an affine function: $f(ax+b)$
    \item Pointwise maximum/supremum: $\max(f_1(x),f_2(x))$
    \item Partial minimization
\end{itemize}

\newpar{}
\ptitle{Concave}

\begin{itemize}
    \item Affine functions: $ ax + b$
    \item Powers: $x^\alpha$ on domain $\mathbb{R}_{++}$ for $0\leq\alpha \leq 1$
    \item Logarithm: $\log(x)$ on domain $\mathbb{R}_{++}$
    \item Entropy: $-x\log(x)$ on domain $\mathbb{R}_{++}$
\end{itemize}

\subsection{Convex Optimization Problems}
\noindent\begin{align*}
    \min_{x\in\mathrm{dom}(f)} & f(x)                                     \\
    \text{subj.\ to\;\; }      & g_i(x)\leq0\quad i=1,\ldots,m            \\
                               & a_i^{\top} x=b_i \quad i=1,\ldots,p      \\
                               & (Ax =b\quad A\in \mathbb{R}^{p\times n})
\end{align*}
\begin{equation*}
    \begin{cases}
        f,g_i                    & \text{convex functions} \\
        \mathrm{dom}(f)          & \text{convex set}       \\
        h_i(x) = a_i^{\top} x -b & \text{affine functions}
    \end{cases}
\end{equation*}
As a result, the feasible set $\mathcal{X}$ is convex.

\subsubsection{Local and Global Optimality}
For any convex optimization problem, any local optimal solution is globally optimal.

\subsubsection{Equivalent Optimization Problems}
Two problems are called equivalent if the solution to one can be (easily) inferred from the solution to the other, and vice versa.
\newpar{}
\ptitle{Introducing Equality Constraints}
\begin{align*}
    \min\;           & f(A_0x + b_0)                               \\
    \mathrm{s.t.} \; & g_i(A_i x + b_i) \leq 0 &  & i = 1,\ldots,m
\end{align*}
is equivalent to
\begin{align*}
    \min\;          & f(y_0)                                   \\
    \mathrm{s.t.}\; & g_i(y_i) \leq 0,   &  & i = 1,\ldots,m   \\
                    & A_i x + b_i = y_i, &  & i = 0,1,\ldots,m
\end{align*}
\newpar{}
\ptitle{Introducing Slack Variables}
\begin{align*}
    \min\;          & f(x)                                \\
    \mathrm{s.t.}\; & A_i x \leq b_i, &  & i = 1,\ldots,m
\end{align*}
is equivalent to
\begin{align*}
    \min\;          & f(x)                                 \\
    \mathrm{s.t.}\; & A_i x +s_i= b_i, &  & i = 1,\ldots,m \\
                    & s_i \geq 0,      &  & i = 1,\ldots,m
\end{align*}

\subsubsection{Linear Program (LP)}\label{optimizer_location_LP}
\begin{align*}
    \min_{x\in\mathbb{R}^n}\; & c^\top x  \\
    \mathrm{s.t.}\;           & Gx \leq h \\
                              & Ax = b
\end{align*}
where the feasible set $\mathcal{P}$ is a polyhedron (convex).

\newpar{}
For the set of optimizers $\mathcal{X}_{opt}$, generally, three cases can occur:
\begin{enumerate}
    \item \textbf{Unbounded} $\mathcal{P}$ is unbounded below
    \item \textbf{Bounded with unique optimizer}: $\mathcal{X}_{opt}$ is a \textbf{singleton}.\ \textit{At least} $n$ constraints are active.
    \item \textbf{Bounded with multiple optimizers}: $\mathcal{X}_{opt}$ is a (bounded or unbounded) subset of $\mathbb{R}^s$. \textit{At least} one constraint is active. In this case, the solution is sensitive to noise. % TODO: Why "s"?.
\end{enumerate}
\begin{center}
    \includegraphics[width=\linewidth]{images/03_LP_cases.png}
\end{center}

\subsubsection{Quadratic Program (QP)}\label{optimizer_location_QP}
The general QP
\begin{align*}
    \min_{x\in\mathbb{R}^n}\; & \frac{1}{2}x^\top H x + q^\top x + r \\
    \mathrm{s.t.}\;           & Gx \leq h                            \\
                              & Ax = b
\end{align*}
is convex if $H>0$.
\newpar{}
Problems with concave objective $H<0$ are quadratic programs, but hard.
% where $H$ is positive semi-definite ($H\succeq 0$).       % TODO: Where is this from? It's basically everything except for the lecture content :O.

\newpar{}
If feasible, in general two cases can occur:
\begin{enumerate}
    \item \textbf{Case 1}: optimizer lies strictly inside the feasible polyhedron. No constraints active.
    \item \textbf{Case 2}: optimizer lies on the boundary of the feasible polyhedron. At least one constraint active.
\end{enumerate}
\begin{center}
    \includegraphics[width=\linewidth]{images/03_QP_cases.png}
\end{center}

\subsection{Optimality Conditions}

\subsubsection{Lagrange Dual Problem}

The standard (possibly non-convex) optimization problem
\begin{align*}
    \min_{x\in\text{dom}(f)} & f(x)                                \\
    \text{subject to}\quad   & g_i(x)\leq 0 \quad i = 1, \ldots, m \\
                             & h_i(x) = 0 \quad i = 1, \ldots m p
\end{align*}
with (primal) decision variable $x$, domain dom$(f)$ and optimal value $p^*$ can be transformed into a dual problem using the \textbf{Lagrangian Function} $L: \mathrm{dom}\left(f\right)\times\mathbb{R}^m\times\mathbb{R}^p\to\mathbb{R}$ is a weighted sum of the objective and constraint functions
\begin{equation*}
    L(x,\lambda,\nu)=f(x)+\sum_{i=1}^{m}\lambda_i g_i(x) + \sum_{i=1}^{p}\nu_i h_i(x)
\end{equation*}
with
\begin{equation*}
    \lambda_i \geq 0
\end{equation*}

The \textbf{dual function} $d$ is then given by
\begin{equation*}
    d(\lambda, \nu) = \underset{x\in\text{dom}(f)}{\text{inf}} L(x,\lambda,\nu)
\end{equation*}

$L(x,\lambda,\nu)$ is affine. Hence, $d(\lambda, \nu)$ (the pointwise infimum in $x$) is always a concave function and is a lower bound for $p^*$
\begin{equation*}
    d(\lambda,\nu)\leq p^*, \quad \forall(\lambda \geq 0, \nu \in \mathbb{R}^p)
\end{equation*}

The \textbf{dual problem}
\begin{gather*}
    \max_{\lambda,\nu} d(\lambda, \nu) \\
    \text{subject to}\quad \lambda \geq 0
\end{gather*}
\begin{itemize}
    \item is \text{convex} ($\min_{\lambda,\nu} -d(\lambda, \nu) $), even if the primal is not. % Does this always hold?
    \item has an optimal value $d^* \leq p^*$.
    \item the point $(\lambda,\nu)$ is \textbf{dual feasible} if $\lambda \geq 0$ and $(\lambda, \nu) \in \text{dom}(d)$.
    \item Can often impose the constraint $(\lambda, \nu)\in \mathrm{dom}(d)$ explicitly. % TODO ?
\end{itemize}

\paragraph{Dual of a Linear Program (LP)}
The primal problem is given by
\begin{align*}
    \min_{x\in\mathbb{R}^n} & c^\top x    \\
    \text{subject to}\quad  & Ax-b = 0    \\
                            & Cx-e \leq 0
\end{align*}

% With the \textbf{duel function}   % sounds Frazzolish :)
With the \textbf{dual function}
\begin{align*}
    d(\lambda, \nu) & = \min_{x\in\mathbb{R}^n} \left[c^\top x + \nu^\top (Ax-b) + \lambda^\top(Cx-e)\right]                              \\
                    & = \min_{x\in\mathbb{R}^n} \left[{\left(A^\top\nu+C^\top\lambda+c\right)}^\top x - b^\top\nu - e^\top \lambda\right] \\
                    & =\begin{cases*}
                           -b^\top\nu - e^\top \lambda & if $A^\top\nu+ C^\top\lambda+c = 0$ \\
                           -\infty                     & otherwise
                       \end{cases*}
\end{align*}
the \textbf{dual problem} is then given by
\begin{align*}
    \max_{\lambda,\nu}     & - b^\top \nu - e^\top\lambda  \\
    \text{subject to}\quad & A^\top\nu+C^\top\lambda+c = 0 \\
                           & \lambda \geq 0
\end{align*}
this optimal value $d^*$ is then a lower bound for the primal problem.
\begin{equation*}
    d^* \leq p^*
\end{equation*}
The dual of a linear program is also a linear program.
\newpar{}
The dual of a mixed integer linear program (MILP) is a linear program.

\paragraph{Dual of a Quadratic Program (QP)}

The primal problem of a QP is
\begin{align*}
    \min_{x\in\mathbb{R}^n} & \frac{1}{2}x^\top Qx + c^\top x \\
    \text{subject to}\quad  & Cx-e \leq 0                     \\
                            & Q \succ 0
\end{align*}

the \textbf{dual function} is therefore

\begin{align*}
    d(\lambda) & = \min_{x\in\mathbb{R}^n}\left[\frac{1}{2}x^\top Q x + c^\top x \lambda^\top(Cx-e)\right]               \\
               & =  \min_{x\in\mathbb{R}^n}\left[\frac{1}{2}x^\top Q x {(c+C^\top\lambda)}^\top x - e^\top\lambda\right]
\end{align*}
for which the unconstrained minimization over $x$ is convex for every $\lambda$. To get the optimal $x$ the dual function is differentiated and set equal to zero (requires $Q>0$)
\begin{gather*}
    Qx + c +C^\top\lambda=0 \Leftrightarrow \\
    x = -Q^{-1}(c + C^\top\lambda)
\end{gather*}
This can then be substituted into the dual function
\begin{equation*}
    d(\lambda) = -\frac{1}{2}{\left(c+C^\top\lambda\right)}^\top Q^{-1}\left(c+C^\top\lambda\right) -e^\top\lambda
\end{equation*}

hence the \textbf{dual problem} is to maximize $d(\lambda)$ over $\lambda\geq0$, or equivalently
\begin{gather*}
    \min_{\lambda} \frac{1}{2}\lambda^\top C Q^{-1}C^\top\lambda+{\left(CQ^{-1}c+e\right)}^\top + \frac{1}{2}c^\top Q^{-1}c \\
    \text{subject to}\quad \lambda \geq 0
\end{gather*}

The \textbf{dual problem} of a QP is another QP.

\subsubsection{Weak and String Duality}

\ptitle{Weak Duality}

It is always true that
\begin{equation*}
    d^* \leq p^*.
\end{equation*}

\newpar{}
\ptitle{Strong Duality}

It is sometimes true that
\begin{equation*}
    p^* = d^*.
\end{equation*}
For non-convex problems this is usually not given.

\newpar{}
\ptitle{Slater Condition}

If for an optimization problem $f$ and all $g_i$ are convex, i.e.\ the problem is \textbf{convex}, then the Slater condition states:
\newpar{}
If there exists at least one \textbf{strictly feasible point}, i.e.
\begin{equation*}
    \left\{x | Ax = b,\; g_i(x) < 0,\; \forall i \in \left\{1, \ldots, m\right\}\right\} \neq \emptyset
\end{equation*}
this \textbf{always implies strong duality}.

\subsubsection{Karush-Kuhn-Tucker (KKT) Conditions}

Assume that $f$, all $g_i$ and $h_i$ are differentiable.
\begin{enumerate}
    \item Primal Feasibility:
          \begin{gather*}
              g_i(x^*) \leq 0 \quad i = 1, \ldots, m \\
              h_i(x^*) = 0 \quad i = 1, \ldots, p
          \end{gather*}
    \item Dual Feasibility:
          \begin{equation*}
              \lambda^* \geq 0
          \end{equation*}
    \item Complementary Slackness:
          \begin{equation*}
              \lambda_i^*g_i(x^*)=0 \quad i = 1, \ldots, m
          \end{equation*}
          implying
          \begin{align*}
              \lambda_{i}^{*} & =0\text{ for every }g_{i}(x^{*})<0.   \\
              g_{i}(x^{*})    & =0\text{ for every }\lambda_{i}^{*}>0
          \end{align*}
    \item Stationarity:
          \begin{align*}
              \nabla_x L(x^*, \lambda^*, \nu^*) =\nabla f(x^*) +\sum_{i=1}^{m}\lambda_i^*\nabla g_i(x^*) \\
              \ldots+\sum_{i=1}^{p}\nu_i^*\nabla h_i(x^*) = 0
          \end{align*}
\end{enumerate}

\newpar{}
\ptitle{Convex Problems}

\textbf{Iff} $(x^*,\lambda^*,\nu^*)$ satisfy the KKT conditions, then they are optimal and Slater's condition holds, hence strong duality holds\begin{equation*}
    p^*=d^*.
\end{equation*}

\newpar{}
\ptitle{General Problems}

For a general optimization problem there is only a necessary condition that states:

If $x^*$ and $(\lambda^*,\nu^*)$ are primal and dual optimal solutions and strong duality holds, then $x^*$ and $(\lambda^*,\nu^*)$ satisfy the KKT conditions.

\begin{examplesection}[Example: KKT Conditions for a QP]
    Given the following QP
    \begin{align*}
        \min_{x\in\mathbb{R}^n} & \frac{1}{2}x^\top Qx + c^\top x \\
        \text{subject to}\quad  & Ax=b                            \\
                                & x\geq 0                         \\
                                & Q \succeq 0
    \end{align*}
    The Lagrangian is
    \begin{equation*}
        L(x,\lambda,\nu) = \frac{1}{2}x^\top Qx +c^\top x +\nu^\top(Ax-b) -\lambda^\top x
    \end{equation*}
    The KKT conditions are:
    \begin{align*}
        \nabla_x L(x,\lambda,\nu) = Qx + A^\top \nu -\lambda +c = 0 &  & \text{KKT 4}                  \\
        Ax=b                                                        &  & \text{KKT 1}                  \\
        x\geq 0                                                     &  & \text{KKT 1}                  \\
        \lambda \geq 0                                              &  & \text{KKT 2}                  \\
        x_i\lambda_i = 0                                            &  & i=1\ldots n \quad\text{KKT 3}
    \end{align*}
\end{examplesection}

\subsubsection{Sensitivity Analysis}

To analyze the sensitivity of a solution one can add a perturbation term to the constraints. The perturbed primal becomes
\begin{align*}
    \min_{x} \quad         & f(x)            \\
    \text{subject to}\quad & g_i(x) \leq u_i \\
                           & h_i(x) = v_i
\end{align*}
and the corresponding dual
\begin{align*}
    \max_{\lambda,\nu}\quad & d(\lambda,\nu) - u^\top \lambda - v^\top \nu \\
    \text{subject to}\quad  & \lambda \geq 0
\end{align*}
where $u$ and $v$ represent the perturbation.

\newpar{}

In the case where strong duality holds for the unperturbed problem, the weak duality of the perturbed problem implies
\begin{align*}
    p^*(u,v) & \geq d^*(\lambda^*,\nu^*) - u^\top \lambda^* -v^\top\nu^* \\
             & = p^*(0,0) - u^\top \lambda^* -v^\top\nu^*
\end{align*}

\newpar{}
\ptitle{Global Sensitivity Analysis}

If a (large) Lagrangian multiplier and the corresponding perturbation have opposite sign, the problem is sensitive to the perturbation. In particular,
\begin{align*}
     & \lambda_i^* \text{ large and } u_i < 0              &  & \Rightarrow \text{(i)}  \\
     & \lambda_i^* \text{ small and } u_i > 0              &  & \Rightarrow \text{(ii)} \\
     & \begin{Bmatrix}
            & \nu^* \text{ large and positive and } v_i < 0 \\
            & \nu^* \text{ large and negative and } v_i > 0
            &\end{Bmatrix} &  & \Rightarrow \text{(i)}                                 \\
     & \begin{Bmatrix}
            & \nu^* \text{ small and positive and } v_i > 0 \\
            & \nu^* \text{ small and negative and } v_i < 0
            &\end{Bmatrix} &  & \Rightarrow \text{(ii)}
\end{align*}
\begin{enumerate}[label=(\roman*), wide=0pt]
    \item $p^*(u,v)$ increases greatly
    \item $p^*(u,v)$ does not decrease much
\end{enumerate}

\newpar{}
\ptitle{Local Sensitivity Analysis}

If in addition $p^*(u,v)$ is differentiable at $(0,0)$, then
\begin{equation*}
    \lambda_i^* = -\frac{\partial p^*(0,0)}{\partial u_i}, \qquad  \nu_i^* = -\frac{\partial p^*(0,0)}{\partial v_i},
\end{equation*}
where
\begin{itemize}
    \item $\lambda_i^*$ is the sensitivity of $p^*$ relative to $i^{th}$ inequality.
    \item $\nu_i^*$ is the sensitivity of $p^*$ relative to $i^{th}$ equality.
\end{itemize}